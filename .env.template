# Ollama Configuration (Local LLM Server)
# Default: http://localhost:11434
# OLLAMA_HOST=http://localhost:11434

# Ollama Model (Default: llama3.2)
# Available models: llama3.2, llama3.1, mistral, codellama, etc.
# Run 'ollama list' to see installed models
# OLLAMA_MODEL=llama3.2

# Optional: Weather API (if using weather skill)
# WEATHER_API_KEY=your_weather_api_key_here

# Optional: Email Configuration (if using email skill)
# EMAIL_ADDRESS=your_email@example.com
# EMAIL_PASSWORD=your_app_password_here
